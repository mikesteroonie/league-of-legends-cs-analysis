<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>League of Legends CS vs. Kills Analysis (2022 Esports Data) | league-of-legends-cs-analysis</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="League of Legends CS vs. Kills Analysis (2022 Esports Data)" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/" />
<meta property="og:url" content="http://localhost:4000/" />
<meta property="og:site_name" content="league-of-legends-cs-analysis" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="League of Legends CS vs. Kills Analysis (2022 Esports Data)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebSite","headline":"League of Legends CS vs. Kills Analysis (2022 Esports Data)","name":"league-of-legends-cs-analysis","url":"http://localhost:4000/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link rel="preload" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700&display=swap" as="style" type="text/css" crossorigin>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <link rel="stylesheet" href="/assets/css/style.css?v=c3db95f7ab30b88fb0f35f03ffff2701a7411035">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">League of Legends CS vs. Kills Analysis (2022 Esports Data)</h1>
      <h2 class="project-tagline"></h2>
      
        <a href="https://github.com/mikesteroonie/league-of-legends-cs-analysis" class="btn">View on GitHub</a>
      
      
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="league-of-legends-cs-vs-kills-analysis-2022-esports-data">League of Legends CS vs. Kills Analysis (2022 Esports Data)</h1>

<h2 id="step-1-introduction">Step 1: Introduction</h2>

<p>The dataset comes from the game League of Legends. This dataset is from the year 2022 and contains 150,588 rows of data of 12,549 unique matches.</p>

<p>To provide some context, in matches items are bought by players and items cost gold. There are 2 main ways to earn gold:</p>

<ol>
  <li>Kill enemies</li>
  <li>Kill minions (Creep Score or CS)</li>
</ol>

<p>There is a third way which is to break down structures but this is trivial and not considered.</p>

<p>Items make players more stronger, so as you get more gold, you have a larger opportunity to get stronger. However I always get into a dispute with my friends about if the creepscore (killing minions) is a good proxy for the gold. I primarily focus on the kills. This is actually a real debate I have with my hometown friends in Korea when I say look I have 10 kills and they say you only have 3 cs per minute(this is bad apparently). They argue good cs means good at being able to kill and I just stole other peoples kills. So I’ve taken it upon myself to analyze if higher creepscore is truly correlated with higher ability to be a threat to kill the enemy team.</p>

<p>“The central question of this project is: Is higher creep score (CS) a stronger predictor of winning than kills at 15 minutes?”</p>

<p>Each match has 10 players, with 5 players on each team.</p>

<p>Here are the columns that I will concern myself with:</p>

<h3 id="early-game-performance-metrics">Early Game Performance Metrics</h3>

<p><strong>Creep Score (CS) Metrics</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">csat10</code>: The creep score (number of minions/monsters killed) by 10 minutes. Reflects early farming efficiency in the early game otherwise known as the laning phase.</li>
  <li><code class="language-plaintext highlighter-rouge">csat15</code>: The creep score by 15 minutes. Shows whether early CS advantages are maintained or improved as the game progresses.</li>
  <li><code class="language-plaintext highlighter-rouge">csat20</code>: The creep score at 20 minutes. Provides insight into sustained farming performance beyond the initial phase.</li>
  <li><code class="language-plaintext highlighter-rouge">opp_csat10</code>: The opponent’s creep score at 10 minutes. Allows calculation of the CS differential. Same for the following columns.</li>
  <li><code class="language-plaintext highlighter-rouge">opp_csat15</code>: The opponent’s creep score at 15 minutes.</li>
  <li><code class="language-plaintext highlighter-rouge">opp_csat20</code>: The opponent’s creep score at 20 minutes.</li>
</ul>

<p><strong>Kill Metrics</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">killsat10</code>: Number of kills secured by the team within the first 10 minutes.</li>
  <li><code class="language-plaintext highlighter-rouge">killsat15</code>: Number of kills at 15 minutes. Helps compare how kill pressure evolves alongside CS.</li>
  <li><code class="language-plaintext highlighter-rouge">killsat20</code>: Number of kills at 20 minutes.</li>
  <li><code class="language-plaintext highlighter-rouge">opp_killsat10</code>: Opponent’s kills at 10 minutes, used to calculate the kill differential.</li>
  <li><code class="language-plaintext highlighter-rouge">opp_killsat15</code>: Opponent’s kills at 15 minutes.</li>
  <li><code class="language-plaintext highlighter-rouge">opp_killsat20</code>: Opponent’s kills at 20 minutes.</li>
</ul>

<p>“While I preserved data from 10, 15, and 20 minutes to enable comprehensive analysis, I focus on the 15-minute mark because it represents the end of the laning phase while still being predictive of the final outcome.”</p>

<hr />

<h2 id="step-2-data-cleaning-and-imputation">Step 2: Data Cleaning and Imputation</h2>

<h3 id="explanation-of-data-cleaning-steps">Explanation of Data Cleaning Steps</h3>

<ol>
  <li><strong>Column Selection</strong>: We specify a list of columns that are directly relevant to the analysis:
    <ul>
      <li>General identifiers and context: <code class="language-plaintext highlighter-rouge">gameid</code>, <code class="language-plaintext highlighter-rouge">teamid</code>, <code class="language-plaintext highlighter-rouge">side</code>, <code class="language-plaintext highlighter-rouge">patch</code>, <code class="language-plaintext highlighter-rouge">result</code>.</li>
      <li>CS metrics: <code class="language-plaintext highlighter-rouge">csat10</code>, <code class="language-plaintext highlighter-rouge">csat15</code>, <code class="language-plaintext highlighter-rouge">csat20</code> and their opponent counterparts (<code class="language-plaintext highlighter-rouge">opp_csat10</code>, etc.).</li>
      <li>Kill metrics: <code class="language-plaintext highlighter-rouge">killsat10</code>, <code class="language-plaintext highlighter-rouge">killsat15</code>, <code class="language-plaintext highlighter-rouge">killsat20</code> and corresponding opponent metrics.</li>
      <li>Overall metrics: <code class="language-plaintext highlighter-rouge">total cs</code>, <code class="language-plaintext highlighter-rouge">teamkills</code>.</li>
      <li>Position: Included so that we can filter out support players (who don’t typically prioritize kills or CS) and help the ADC, which is a position that is considered. We will use the omission of support as a means of imputation.
This ensures that we only load the data necessary for hypothesis testing.</li>
    </ul>
  </li>
  <li><strong>Data Type Conversion</strong>: Many columns in the raw data that should be numeric might be read as strings. We convert these columns to numeric using <code class="language-plaintext highlighter-rouge">pd.to_numeric</code> with <code class="language-plaintext highlighter-rouge">errors='coerce'</code>, which automatically replaces any non-numeric entries with <code class="language-plaintext highlighter-rouge">NaN</code>. This is critical for numerical analyses.</li>
  <li><strong>Filtering Rows</strong>: The dataset includes rows for all positions, including aggregated ‘team’ rows. We filter out ‘team’ rows initially. We also filter out ‘sup’ (support) position rows <em>after</em> imputation, as their CS/kill patterns differ significantly. Also I noticed there were an obscene amount of rows where CS was 0, so we will also remove these rows as these likely represent incomplete game records.</li>
  <li><strong>Imputation</strong>: Missing values in key numeric columns (<code class="language-plaintext highlighter-rouge">csat*</code>, <code class="language-plaintext highlighter-rouge">killsat*</code>, <code class="language-plaintext highlighter-rouge">total cs</code>, etc.) are imputed using a cascading median strategy (details below).</li>
  <li><strong>Index Reset and Renaming</strong>: After filtering and imputation, the index is reset for easier handling. The column <code class="language-plaintext highlighter-rouge">'total cs'</code> is renamed to <code class="language-plaintext highlighter-rouge">'total_cs'</code> for consistency.</li>
</ol>

<h3 id="head-of-cleaned-dataframe">Head of Cleaned DataFrame</h3>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| position | result | csat10 | opp_csat10 | csat15 | opp_csat15 | killsat10 | opp_killsat10 | killsat15 | opp_killsat15 | total_cs | teamkills |
| :------- | -----: | -----: | ---------: | -----: | ---------: | --------: | ------------: | --------: | ------------: | -------: | --------: |
| top      |      0 |     89 |         81 |    135 |        121 |         0 |             0 |         0 |             0 |      231 |         9 |
| jng      |      0 |     58 |         63 |     89 |        100 |         1 |             0 |         2 |             0 |      148 |         9 |
| mid      |      0 |     81 |         81 |    120 |        119 |         0 |             0 |         0 |             3 |      193 |         9 |
| bot      |      0 |     78 |         90 |    115 |        149 |         1 |             0 |         2 |             3 |      226 |         9 |
| top      |      1 |     81 |         89 |    121 |        135 |         0 |             0 |         0 |             0 |      229 |        19 |
</code></pre></div></div>

<h3 id="univariate-analysis">Univariate Analysis</h3>

<p>Here we look at the distributions of key team-level metrics: Total CS and Total Kills, separated by match outcome (Win/Loss).</p>

<p><strong>Distribution of Team-Level Total CS by Outcome</strong></p>

<iframe src="assets/team_cs_distribution.html" width="800" height="600" frameborder="0"></iframe>

<p><em>Interpretation:</em> This histogram shows that CS distributions form a relatively normal curve centered around 900-1000 total CS per team. Winning teams (green) generally have higher CS than losing teams (red). Wow, I guess I might be on the path towards being wrong. The box plots at the top confirm that the median CS for winning teams is clearly higher than for losing teams. There appears to be a CS advantage associated with winning, supporting the idea that farming efficiency correlates with success. Ouch.</p>

<p><strong>Distribution of Team-Level Total Kills by Outcome</strong></p>

<iframe src="assets/team_kills_distribution.html" width="800" height="600" frameborder="0"></iframe>

<p><em>Interpretation:</em> This histogram shows the distribution of total team kills. Similar to CS, winning teams (green) tend to have higher kill counts than losing teams (red), although the distributions overlap significantly. The median number of kills is higher for winning teams, suggesting that securing more kills is also associated with winning.</p>

<h3 id="bivariate-analysis">Bivariate Analysis</h3>

<p>This plot examines the relationship between a player’s role (position), their CS at 15 minutes, and the match outcome. Note: the reason why I will be looking at the 15 minute mark for the following graphs is because 15 minutes usually marks the end of the laning phase where most CS is collected. After 15 minutes players roam to other parts of the map and get into team fights and whatnot.</p>

<p><strong>CS at 15 Minutes by Position and Outcome</strong></p>

<iframe src="assets/cs_by_position_outcome.html" width="800" height="600" frameborder="0"></iframe>

<p><em>Interpretation:</em> This box plot reveals that Mid and Top laners generally achieve the highest CS by 15 minutes, followed closely by Bot lane ADCs. Junglers have significantly lower CS, as expected. Within each role, winning players (green) tend to have a higher median CS than losing players (red). The difference appears most pronounced in the Top lane, suggesting that a CS advantage in this lane might be particularly impactful for securing a win. This aligns with competitive LoL dynamics where lane dominance through CS creates pressure.</p>

<h3 id="interesting-aggregates">Interesting Aggregates</h3>

<p>This combined chart shows the relationship between CS brackets at 15 minutes and the overall win rate for players within those brackets.</p>

<p><strong>Win Rate by CS at 15 Minutes Brackets</strong></p>

<iframe src="assets/win_rate_by_cs_bracket.html" width="800" height="600" frameborder="0"></iframe>

<p><em>Interpretation:</em> This chart strongly demonstrates a positive correlation between CS at 15 minutes and win rate. The win rate climbs steadily from around 50% in the lower CS brackets to nearly 70% in the highest bracket. Most games fall into the middle brackets (e.g., 115-153 CS), but achieving exceptionally high CS significantly increases the likelihood of winning. This highlights that strong early-game farming is a robust predictor of match success in this dataset. But I will address that the small amount of sample size in the beginning of the graph signifying a high win rate respite having low CS could indicate that there are a decent amount of games despite having low CS there is usually another carry on the team, and doing this bad at 15 minutes could mean there is an x factor on your own team. But the trend for 38.4 cs + remains true.</p>

<p><strong>Average CS at Different Timestamps by Position and Outcome</strong></p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| position | csat10_0 | csat10_1 | csat15_0 | csat15_1 | csat20_0 | csat20_1 | cs_diff_10 | cs_diff_15 | cs_diff_20 |
| :------- | -------: | -------: | -------: | -------: | -------: | -------: | ---------: | ---------: | ---------: |
| bot      |  77.6326 |  79.7207 |  124.943 |  128.997 |  171.942 |  178.213 |    2.08813 |    4.05387 |    6.27169 |
| jng      |  62.0141 |   63.216 |   93.571 |  96.0065 |  122.054 |  126.875 |    1.20197 |    2.43545 |    4.82102 |
| mid      |  83.3052 |  85.1219 |  134.034 |  137.689 |  177.165 |  182.729 |    1.81672 |    3.65451 |    5.56431 |
| top      |  75.6975 |  77.8944 |  122.852 |  126.971 |  165.039 |  171.271 |    2.19683 |    4.11893 |    6.23265 |
</code></pre></div></div>

<p><em>Interpretation:</em> This table provides the average CS values at 10, 15, and 20 minutes for each position, split by whether the team won (1) or lost (0). The <code class="language-plaintext highlighter-rouge">cs_diff</code> columns show the average CS advantage for winning players in each role at each time point. This numerically reinforces the observations from the box plot, showing consistent CS leads for winners across most roles and time points.</p>

<h3 id="imputation">Imputation</h3>

<p>A significant portion of the data had missing values, particularly for the CS and Kill metrics at specific timestamps.</p>

<p><strong>Missing Data Summary:</strong></p>

<ul>
  <li>Total rows: 150,588</li>
  <li>Rows with at least one missing value in key columns: 45,933 (~30.5%)</li>
  <li>Missing percentages for <code class="language-plaintext highlighter-rouge">csat*</code> / <code class="language-plaintext highlighter-rouge">killsat*</code> columns: ~15-16%</li>
</ul>

<p>Dropping these rows would discard too much information. Therefore, imputation was necessary.</p>

<p><strong>Imputation Strategy:</strong></p>

<p>At first I did median imputation but because such a large amount of rows were missing data the graph looked really awkward as the median value frequency count was so so high. So with my background knowledge in League of Legends, I decided to use a different impute strategy where I get the median by role and team average. Because some teams like to play aggressive and some play passively. Furthermore ADC’s typically have more kills than other roles so I thought this would be a good strategy.</p>

<p>A more nuanced, cascaded median imputation strategy was adopted:</p>

<ol>
  <li>For a missing value, first try imputing using the median for that specific <code class="language-plaintext highlighter-rouge">position</code> and <code class="language-plaintext highlighter-rouge">champion</code> combination.</li>
  <li>If that combination isn’t available or its median is NaN, fall back to the median for the player’s <code class="language-plaintext highlighter-rouge">position</code>.</li>
  <li>If that fails, use the median for the player’s <code class="language-plaintext highlighter-rouge">teamid</code>.</li>
  <li>As a final fallback, use the overall median for the column across all non-support players.</li>
</ol>

<p>This strategy leverages domain knowledge (different roles/champions/teams have different typical stats) to provide more realistic imputed values than a simple overall median. The reason why I chose the position + champion combination is because some positions have an opportunity to get more CS than others, and some champions have better farming mechanics(i.e it’s easier to kill minons with their abilities) than others!</p>

<p><strong>Imputation Quality Report</strong></p>

<!--
INSTRUCTIONS:
1. In your Python script/notebook, after creating `imputation_report`, add:
   `print(imputation_report.to_markdown(index=False))`
2. Copy the Markdown table output from the console.
3. Paste the copied Markdown table below this comment block.
-->

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code>| column        | missing_values | original_mean | original_median | imputed_mean | imputed_median | percent_change |
| :------------ | -------------: | ------------: | --------------: | -----------: | -------------: | -------------: |
| total_cs      |          25098 |       198.968 |             214 |      239.868 |            237 |        20.5561 |
| csat10        |          22716 |        104.83 |              77 |      75.5753 |             78 |        27.9071 |
| csat15        |          22716 |       167.489 |             124 |      120.633 |            126 |        27.9758 |
| csat20        |          23172 |       224.578 |             167 |      161.911 |            169 |        27.9045 |
| opp_csat10    |          22716 |        104.83 |              77 |      75.5935 |             77 |        27.8898 |
| opp_csat15    |          22716 |       167.489 |             124 |      120.677 |            125 |        27.9493 |
| opp_csat20    |          23172 |       224.578 |             167 |      161.948 |            169 |        27.8879 |
| killsat10     |          22716 |       0.72826 |               0 |      0.42483 |              0 |        41.6651 |
| killsat15     |          22716 |       1.35872 |               1 |       0.8852 |              1 |        34.8504 |
| killsat20     |          23172 |       2.15704 |               1 |      1.43643 |              1 |        33.4075 |
| opp_killsat10 |          22716 |       0.72826 |               0 |     0.417548 |              0 |        42.6649 |
| opp_killsat15 |          22716 |       1.35872 |               1 |     0.883681 |              1 |        34.9622 |
| opp_killsat20 |          23172 |       2.15704 |               1 |       1.4194 |              1 |        34.1972 |
</code></pre></div></div>

<p><em>Interpretation:</em> This table compares the mean and median of key columns before and after imputation (calculated on the non-missing original values vs. the fully imputed column). The goal is for the imputed statistics to be reasonably close to the original ones, indicating the imputation hasn’t drastically changed the central tendency of the data. Small percentage changes suggest the imputation was successful in preserving the overall data characteristics.</p>

<p><strong>Visualizing Imputation Effect (Example: CS at 15 Minutes)</strong></p>

<!--
INSTRUCTIONS:
Option 1 (Interactive Plot - Recommended if possible):
1. Modify your `visualize_imputation_effect` function (or create a new one) to generate interactive Plotly histograms comparing distributions before (using `df_original[col].dropna()`) and after imputation (`df_cleaned[col]`).
2. Save these plots to HTML files in the `assets` folder (e.g., `assets/imputation_csat10_compare.html`).
3. Embed using the iframe structure below. Repeat for other key columns if desired.

Option 2 (Static PNG Image):
1. Ensure your current `visualize_imputation_effect` saves `imputation_effect.png` to the `assets` folder.
2. Use the standard Markdown image tag: `![Imputation Effect](assets/imputation_effect.png)` instead of the iframe.
-->

<iframe src="assets/imputation_csat10_compare.html" width="800" height="400" frameborder="0"></iframe>

<p><em>Interpretation:</em> Comparing the distribution of <code class="language-plaintext highlighter-rouge">csat10</code> before imputation (orange, excluding NaNs) and after imputation (blue) shows how the imputation strategy filled the gaps. Ideally, the shape of the blue histogram should look like a “filled-in” version of the orange one, without introducing extreme artificial peaks, demonstrating that the imputation maintained the original data’s general distribution. Getting rid of these artificial peaks at the bottom and the top help us better predict, as these are not a typically representative of a normal League of Legends game. I don’t think blowouts are good to consider here.</p>

<h2 id="step-3-framing-a-prediction-problem">Step 3: Framing a Prediction Problem</h2>

<p><strong>Prediction Problem:</strong> Can we predict the final outcome (win or loss) of a League of Legends match based <em>only</em> on performance metrics measured at the 15-minute mark?</p>

<p><strong>Motivation:</strong> This problem aims to test the hypothesis that the early-to-mid game phase (specifically, the state at 15 minutes) is significantly predictive of the final match result. It explores whether early advantages in creep score (CS), kills, gold, or experience translate reliably into victories, addressing the common debate about the importance of the “laning phase” versus later team fights.</p>

<p><strong>Prediction Type:</strong> This is a <strong>Binary Classification</strong> problem.</p>

<p><strong>Response Variable:</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">result</code>: A binary variable indicating whether the team won (<code class="language-plaintext highlighter-rouge">1</code>) or lost (<code class="language-plaintext highlighter-rouge">0</code>) the match.</li>
  <li><em>Justification:</em> This variable directly represents the match outcome we want to predict.</li>
</ul>

<p><strong>Evaluation Metric:</strong></p>

<ul>
  <li><strong>F1-Score:</strong> We will primarily use the F1-score to evaluate our models.</li>
  <li><em>Justification:</em> The F1-score provides a balance between Precision (the proportion of predicted wins that were actual wins) and Recall (the proportion of actual wins that were correctly predicted). This is useful because we care about both accurately identifying winning scenarios and not misclassifying losses as wins (and vice-versa). It’s also generally more robust to potential class imbalance (where wins might be slightly more or less frequent than losses) than simple accuracy. We choose it over accuracy because F1 also balances the csot of false-wins and false-losses, so we won’t sacrifice catching true wins just to boost overall percent correct.</li>
</ul>

<p>I chose f1 over Auroc as well because auroc is good for understanding separability before pickinga deciison threshold, but doesn’t tell us how our final win loss cutoff actually performs. Since the end goal is a concrete classifier, we need a metric that reflects performance at the cutoff, and this is exactly what F1 does. I will still include auroc and accuracy just to show overall performance of the model however.</p>

<p><strong>Features at Prediction Time:</strong></p>

<ul>
  <li>We will only use features derived from data available <em>at</em> the 15-minute mark (e.g., <code class="language-plaintext highlighter-rouge">csat15</code>, <code class="language-plaintext highlighter-rouge">opp_csat15</code>, <code class="language-plaintext highlighter-rouge">killsat15</code>, <code class="language-plaintext highlighter-rouge">opp_killsat15</code>, <code class="language-plaintext highlighter-rouge">side</code>). The final match <code class="language-plaintext highlighter-rouge">result</code> is unknown at this point, making it a valid prediction target based on these early-game indicators.</li>
</ul>

<hr />

<h2 id="step-4-baseline-model">Step 4: Baseline Model</h2>

<p>To establish a performance baseline, we start with a simple Logistic Regression model.</p>

<p><strong>Model Description:</strong></p>

<ul>
  <li>An <code class="language-plaintext highlighter-rouge">sklearn</code> Pipeline combining preprocessing and a Logistic Regression classifier.</li>
</ul>

<p><strong>Features Used:</strong></p>

<ul>
  <li>The baseline model uses <strong>two</strong> features known at 15 minutes:
    <ol>
      <li><code class="language-plaintext highlighter-rouge">cs_diff_15</code>: <strong>Quantitative</strong>. Represents the difference between a player’s CS and their direct opponent’s CS at 15 minutes (<code class="language-plaintext highlighter-rouge">csat15 - opp_csat15</code>). This feature was left as-is (no scaling applied in this baseline).</li>
      <li><code class="language-plaintext highlighter-rouge">side</code>: <strong>Nominal</strong>. Represents the side the player’s team played on (‘Blue’ or ‘Red’). This was encoded using <code class="language-plaintext highlighter-rouge">OneHotEncoder</code>, dropping one category to prevent multicollinearity. This results in one binary feature (e.g., <code class="language-plaintext highlighter-rouge">side_Red</code>).
        <ul>
          <li>In total, the model uses <strong>1 quantitative feature</strong> and <strong>1 nominal feature</strong> (0 ordinal features).</li>
          <li>To those not familiar with league of legends, this actually kind of matters because of the way the map is set up red side can have less vision than blue at certain spots in the map.</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p><strong>Performance:</strong></p>

<ul>
  <li>The model was trained on 80% of the (non-support) player data and evaluated on the remaining 20%.</li>
  <li><strong>Accuracy:</strong> 0.5817</li>
  <li><strong>F1-Score (Weighted Avg):</strong> 0.5805</li>
  <li>
    <p><strong>ROC AUC:</strong> 0.6141</p>
  </li>
  <li>
    <p><strong>Classification Report:</strong></p>

    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>             precision    recall  f1-score   support

          0       0.58      0.58      0.58     10043
          1       0.58      0.58      0.58     10036

   accuracy                           0.58     20079
  macro avg       0.58      0.58      0.58     20079
weighted avg       0.58      0.58      0.58     20079
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Feature Importance:</strong> The coefficients from the Logistic Regression indicate the importance and direction of influence for each feature. A higher absolute coefficient suggests stronger influence.</p>

    <table>
      <thead>
        <tr>
          <th style="text-align: left">Feature</th>
          <th style="text-align: right">Coefficient</th>
          <th style="text-align: right">Abs_Coefficient</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <td style="text-align: left">side_Red</td>
          <td style="text-align: right">-0.201498</td>
          <td style="text-align: right">0.201498</td>
        </tr>
        <tr>
          <td style="text-align: left">cs_diff_15</td>
          <td style="text-align: right">0.015363</td>
          <td style="text-align: right">0.015363</td>
        </tr>
      </tbody>
    </table>

    <p><em>(Interpretation: The model gives slightly more weight (based on absolute coefficient) to the <code class="language-plaintext highlighter-rouge">side</code> played than the <code class="language-plaintext highlighter-rouge">cs_diff_15</code>. A positive coefficient for <code class="language-plaintext highlighter-rouge">cs_diff_15</code> suggests a higher CS difference increases the log-odds of winning. A negative coefficient for <code class="language-plaintext highlighter-rouge">side_Red</code> suggests playing on the Red side decreases the log-odds of winning compared to the Blue side, according to this model.)</em></p>
  </li>
</ul>

<p><strong>Assessment:</strong></p>

<ul>
  <li>The baseline model achieves an F1-score of <code class="language-plaintext highlighter-rouge">0.5805</code> and an ROC AUC of <code class="language-plaintext highlighter-rouge">0.6141</code>. Given that a random guessing model would achieve an F1/AUC around 0.5, this baseline performance indicates that even just the CS difference at 15 minutes and the side played on have <em>some</em> predictive power regarding the match outcome.</li>
  <li>The feature importance shows that both <code class="language-plaintext highlighter-rouge">cs_diff_15</code> and <code class="language-plaintext highlighter-rouge">side</code> contribute to the prediction, with <code class="language-plaintext highlighter-rouge">side</code> having a slightly larger coefficient magnitude.</li>
  <li>However, the overall performance (<code class="language-plaintext highlighter-rouge">0.5805</code> F1-score) is quite low, indicating the model is only slightly better than random guessing. I guess the positive correlation between cs and winning demonstrated by figure 1.4 indicates late-game cs beyond the laning phase also have influence as well…There is significant room for improvement by incorporating more relevant features (like kill differences, gold differences, etc.) which will be explored in Step 5.</li>
</ul>

<hr />

<h2 id="step-5-final-model">Step 5: Final Model</h2>

<p>Building upon the baseline, the final model aims to improve prediction accuracy by incorporating more sophisticated features and optimizing model parameters.</p>

<p><strong>Feature Engineering:</strong></p>

<p>In addition to the baseline features (<code class="language-plaintext highlighter-rouge">cs_diff_15</code>, <code class="language-plaintext highlighter-rouge">side</code>), the final model includes:</p>

<ul>
  <li>
    <p><strong>Original Difference Metrics:</strong></p>

    <ul>
      <li><code class="language-plaintext highlighter-rouge">kills_diff_15</code>: Difference in kills at 15 minutes. This is what I believe contributes to direct combat success.</li>
      <li><code class="language-plaintext highlighter-rouge">gold_diff_15</code>: Difference in gold earned at 15 minutes. Reflects overall economic advantage.</li>
      <li><code class="language-plaintext highlighter-rouge">xp_diff_15</code>: Difference in experience points at 15 minutes. Indicates champion level and power disparities.</li>
    </ul>

    <p>I reimpute to get the above mentioned metrics.</p>
  </li>
  <li>
    <p><strong>Newly Engineered Features:</strong> To capture more nuanced game dynamics, two interaction/ratio features were created:</p>
    <ol>
      <li><code class="language-plaintext highlighter-rouge">gold_efficiency</code>: Calculated as <code class="language-plaintext highlighter-rouge">gold_diff_15 / (abs(cs_diff_15) + 10)</code>.
        <ul>
          <li><em>Justification:</em> This feature aims to measure how effectively a player translates their farming advantage (or lack thereof) into a <em>gold</em> advantage. A high ratio might indicate a player securing gold through objectives, kills, or efficient trading beyond just CS, reflecting strong map play or combat effectiveness relative to their farming. The <code class="language-plaintext highlighter-rouge">+ 10</code> avoids division by zero and dampens the ratio for very small CS differences.</li>
        </ul>
      </li>
      <li><code class="language-plaintext highlighter-rouge">gold_xp_interaction</code>: Calculated as <code class="language-plaintext highlighter-rouge">gold_diff_15 * xp_diff_15</code>.
        <ul>
          <li><em>Justification:</em> In League of Legends, gold (items) and experience (levels/skills) advantages often work synergistically. This interaction term captures that combined effect. A large positive value signifies a strong dual advantage (high gold <em>and</em> high XP diff), while a large negative value indicates a severe deficit in both. This should provide a stronger signal of dominance or disadvantage than either metric alone.</li>
        </ul>
      </li>
    </ol>
  </li>
</ul>

<p>These features were chosen because they represent key aspects of early-game performance (combat, economy, levels) and interactions between them that are commonly understood to influence match outcomes in League of Legends.</p>

<p><strong>Modeling Algorithm and Hyperparameter Tuning:</strong></p>

<ul>
  <li><strong>Algorithm:</strong> Logistic Regression was retained for the final model due to its suitability for binary classification and the interpretability of its coefficients.</li>
  <li><strong>Hyperparameter Tuning Method:</strong> <code class="language-plaintext highlighter-rouge">GridSearchCV</code> with 5-fold cross-validation was used to systematically search for the best model configuration based on f1 (the chosen <code class="language-plaintext highlighter-rouge">scoring</code> metric for <code class="language-plaintext highlighter-rouge">GridSearchCV</code>). Also I binarized predictions at the default 0.5 probability cutoff to compute F1. Furthermore after CV I refit the best estimator on the full training split before evaluating on the test set.””</li>
  <li><strong>Parameters Tuned:</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">C</code> (Inverse of regularization strength): <code class="language-plaintext highlighter-rouge">[0.01, 0.1, 1.0, 10.0, 100.0]</code></li>
      <li><code class="language-plaintext highlighter-rouge">penalty</code> (Regularization type): <code class="language-plaintext highlighter-rouge">['l1', 'l2']</code></li>
      <li><code class="language-plaintext highlighter-rouge">solver</code> (Optimization algorithm): <code class="language-plaintext highlighter-rouge">['liblinear', 'saga']</code></li>
    </ul>
  </li>
  <li><strong>Best Hyperparameters Found:</strong>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">C</code>: <code class="language-plaintext highlighter-rouge">1.0</code></li>
      <li><code class="language-plaintext highlighter-rouge">penalty</code>: <code class="language-plaintext highlighter-rouge">'l1'</code></li>
      <li><code class="language-plaintext highlighter-rouge">solver</code>: <code class="language-plaintext highlighter-rouge">'saga'</code>
<em>(Interpretation: The optimal C value of <code class="language-plaintext highlighter-rouge">1.0</code> suggests a moderate level of regularization was optimal. The L1 penalty (‘lasso’) was selected, which can sometimes perform feature selection by shrinking some coefficients exactly to zero, although that didn’t happen significantly here.)</em></li>
    </ul>
  </li>
  <li><strong>Feature Transformation:</strong> A <code class="language-plaintext highlighter-rouge">ColumnTransformer</code> was used within the pipeline:
    <ul>
      <li>Original numeric features (<code class="language-plaintext highlighter-rouge">cs_diff_15</code>, <code class="language-plaintext highlighter-rouge">kills_diff_15</code>, etc.) were scaled using <code class="language-plaintext highlighter-rouge">StandardScaler</code>.</li>
      <li>Engineered numeric features (<code class="language-plaintext highlighter-rouge">gold_efficiency</code>, <code class="language-plaintext highlighter-rouge">gold_xp_interaction</code>) were transformed using <code class="language-plaintext highlighter-rouge">QuantileTransformer</code> (outputting to a normal distribution) to handle potential skewness or outliers.</li>
      <li>The categorical <code class="language-plaintext highlighter-rouge">side</code> feature was processed using <code class="language-plaintext highlighter-rouge">OneHotEncoder</code> (dropping the first category).</li>
    </ul>
  </li>
</ul>

<p><strong>Final Model Performance:</strong></p>

<ul>
  <li><strong>Accuracy:</strong> 0.6272</li>
  <li><strong>F1-Score (Weighted Avg):</strong> 0.6272 <em>(Note: Macro avg F1 is 0.6272, value for class 1 is 0.6274)</em></li>
  <li>
    <p><strong>ROC AUC:</strong> 0.6870</p>
  </li>
  <li>
    <p><strong>Classification Report:</strong></p>

    <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>             precision    recall  f1-score   support

          0       0.63      0.63      0.63     12535
          1       0.63      0.63      0.63     12563

   accuracy                           0.63     25098
  macro avg       0.63      0.63      0.63     25098
weighted avg       0.63      0.63      0.63     25098
</code></pre></div>    </div>
  </li>
  <li>
    <p><strong>Feature Importance:</strong>
| Feature | Coefficient | Abs_Coefficient |
|:———————-|————–:|——————:|
| gold_diff_15 | 0.703971 | 0.703971 |
| cs_diff_15 | -0.308589 | 0.308589 |
| xp_diff_15 | 0.235688 | 0.235688 |
| side_Red | -0.154401 | 0.154401 |
| gold_efficiency | 0.125449 | 0.125449 |
| kills_diff_15 | -0.098009 | 0.098009 |
| gold_xp_interaction | 0.005903 | 0.005903 |</p>

    <p><em>(Interpretation: Based on the coefficients’ absolute values, the most influential features in predicting a win at 15 minutes were <code class="language-plaintext highlighter-rouge">gold_diff_15</code>, <code class="language-plaintext highlighter-rouge">cs_diff_15</code>, and <code class="language-plaintext highlighter-rouge">xp_diff_15</code>. The positive coefficient for <code class="language-plaintext highlighter-rouge">gold_diff_15</code> strongly aligns with game knowledge – having more gold directly translates to better items and thus a higher chance of winning. Interestingly, <code class="language-plaintext highlighter-rouge">cs_diff_15</code> has a negative coefficient, suggesting that *after accounting for gold and XP differences</em>, a higher CS difference alone might slightly decrease the odds of winning in this model’s view (perhaps capturing scenarios where a player focuses too much on CS without converting it effectively, though this requires careful interpretation). The <code class="language-plaintext highlighter-rouge">xp_diff_15</code> also positively contributes as expected. <code class="language-plaintext highlighter-rouge">side_Red</code> maintains its negative coefficient, and the engineered features contribute, but less strongly than the primary difference metrics.)*</p>
  </li>
</ul>

<p><strong>Comparison to Baseline:</strong></p>

<p>The final model demonstrated a clear improvement over the baseline:</p>

<table>
  <thead>
    <tr>
      <th style="text-align: left">Metric</th>
      <th style="text-align: right">Baseline Model</th>
      <th style="text-align: right">Final Model</th>
      <th style="text-align: right">Improvement</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: left">Accuracy</td>
      <td style="text-align: right">0.5817</td>
      <td style="text-align: right">0.6272</td>
      <td style="text-align: right">+0.0455</td>
    </tr>
    <tr>
      <td style="text-align: left">F1 Score (Wgt)</td>
      <td style="text-align: right">0.5805</td>
      <td style="text-align: right">0.6272</td>
      <td style="text-align: right">+0.0467</td>
    </tr>
    <tr>
      <td style="text-align: left">ROC AUC</td>
      <td style="text-align: right">0.6141</td>
      <td style="text-align: right">0.6870</td>
      <td style="text-align: right">+0.0729</td>
    </tr>
  </tbody>
</table>

<ul>
  <li><em>Discussion:</em> The increase in F1-score (from <code class="language-plaintext highlighter-rouge">0.5805</code> to <code class="language-plaintext highlighter-rouge">0.6272</code>) and ROC AUC (from <code class="language-plaintext highlighter-rouge">0.6141</code> to <code class="language-plaintext highlighter-rouge">0.6870</code>) shows that incorporating the additional difference features (kills, gold, XP) and the engineered features, along with hyperparameter tuning, allowed the model to capture the game state at 15 minutes more effectively than the simple two-feature baseline. The improvement, while modest, highlights the predictive value of a more comprehensive view of early-game performance, particularly the economic (<code class="language-plaintext highlighter-rouge">gold_diff_15</code>) and level (<code class="language-plaintext highlighter-rouge">xp_diff_15</code>) advantages.</li>
</ul>

<p><strong>Conclusion:</strong></p>

<p>The final Logistic Regression model, enhanced with additional and engineered features reflecting key game interactions and tuned hyperparameters, outperforms the baseline model in predicting match outcomes based on the 15-minute mark. While still far from perfect (accuracy ~63%), the model achieves an F1-score of <code class="language-plaintext highlighter-rouge">0.6272</code> and ROC AUC of <code class="language-plaintext highlighter-rouge">0.6870</code>, demonstrating that early-game advantages, particularly gold difference, are statistically significant indicators of eventual success. With my previous of League of Legends, one thing that may contribute early laning phase being a modest predictor for winning is the fact that these are data from pro games. And in pro games there are a lot of upsets in the late stages because pro’s know how to capitalize on mistakes much more. In casual games there is more snowballing meaning that if someone has a big advantage early on, inexprerienced players have low probability of coming back.</p>

<p>The feature importance aligns with game knowledge, emphasizing the impact of gold and experience differentials. The negative coefficient for CS difference warrants further investigation but might suggest complexities beyond simple farm counts when other advantages are considered.</p>


      <footer class="site-footer">
        
          <span class="site-footer-owner"><a href="https://github.com/mikesteroonie/league-of-legends-cs-analysis">league-of-legends-cs-analysis</a> is maintained by <a href="https://github.com/mikesteroonie">mikesteroonie</a>.</span>
        
        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
      </footer>
    </main>
  </body>
</html>
